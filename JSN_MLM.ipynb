{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "EL7na31jgicY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import RobertaTokenizerFast\n",
        "import torch\n",
        "import json\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv(\"jsn_smiles.csv\")\n",
        "smiles_strings = df[\"SMILES_COLUMN\"].tolist()\n",
        "\n",
        "# Load custom vocab from the uploaded JSON file\n",
        "with open(\"vocab.json\", \"r\") as f:\n",
        "    custom_vocab = json.load(f)\n",
        "\n",
        "# Initialize a tokenizer with custom vocab\n",
        "custom_tokenizer = RobertaTokenizerFast(\n",
        "    vocab_file=\"vocab.json\",\n",
        "    merges_file=\"merges.txt\",\n",
        "    model_max_length=512,\n",
        ")\n",
        "\n",
        "# Tokenize SMILES strings\n",
        "encoded_inputs = custom_tokenizer(\n",
        "    smiles_strings,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=512,\n",
        "    return_tensors=\"pt\",  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "\n",
        "# Define the excluded token IDs\n",
        "excluded_token_ids = [591, 592, 593, 594]\n",
        "\n",
        "# Create a mask to exclude specific token IDs from being masked\n",
        "excluded_mask = torch.ones_like(encoded_inputs[\"input_ids\"], dtype=torch.bool)\n",
        "for token_id in excluded_token_ids:\n",
        "    excluded_mask &= (encoded_inputs[\"input_ids\"] != token_id)\n",
        "\n",
        "# Mask a percentage of the tokens (15%) excluding the specified token IDs\n",
        "rand = torch.rand(encoded_inputs[\"input_ids\"].shape)\n",
        "mask_ids = (rand < 0.15) & encoded_inputs[\"attention_mask\"].bool() & excluded_mask\n",
        "\n",
        "input_ids = encoded_inputs[\"input_ids\"]\n",
        "attention_mask = encoded_inputs[\"attention_mask\"]\n",
        "\n",
        "\n",
        "#JSN\n",
        "# Create a copy of the input_ids to use for MLM prediction\n",
        "labels = input_ids.clone()\n",
        "\n",
        "# Apply the masking\n",
        "input_ids[mask_ids] = custom_tokenizer.mask_token_id\n",
        "\n",
        "encodings = {\n",
        "    'input_ids' : input_ids,\n",
        "    'attention_mask': attention_mask,\n",
        "    'labels' : labels,\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Dataset (torch.utils.data.Dataset) :\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "    def __len__(self):\n",
        "        return self.encodings['input_ids'].shape[0]\n",
        "    def __getitem__(self,i):\n",
        "        return {\n",
        "            key:tensor[i] for key, tensor in self.encodings.items()\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "# Create DataLoader\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "dataset = Dataset(encodings)\n",
        "batch_size = 16\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "from transformers import RobertaConfig\n",
        "config = RobertaConfig(\n",
        "    vocab_size = 596,\n",
        "    max_position_embeddings=514,\n",
        "    hidden_size = 768,\n",
        "    num_attention_heads=12,\n",
        "    num_hidden_layers=6,\n",
        "    type_vocab_size=1\n",
        ")\n",
        "\n",
        "from transformers import RobertaForMaskedLM\n",
        "model = RobertaForMaskedLM(config)\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "from transformers import AdamW\n",
        "optim = AdamW(model.parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "epoch = 2\n",
        "\n",
        "\n",
        "loop = tqdm(dataloader, leave = True)\n",
        "for batch in loop:\n",
        "    optim.zero_grad()\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    labels = batch['labels'].to(device)\n",
        "    outputs = model(input_ids, attention_mask = attention_mask, labels = labels)\n",
        "    loss = outputs.loss\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    loop.set_description(f'Epoch: {epoch}')\n",
        "    loop.set_postfix(loss = loss.item())\n",
        "\n",
        "\n",
        "model.save_pretrained(\"harikrishna_jsn\")\n",
        "\n"
      ],
      "metadata": {
        "id": "WLUgkDeTgJJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ntPdEQagF8k"
      },
      "outputs": [],
      "source": [
        "# Initialize variables for accuracy calculation\n",
        "total_tokens = 0\n",
        "correct_predictions = 0\n",
        "\n",
        "# Loop through the batches in the DataLoader\n",
        "for batch in dataloader:\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    labels = batch['labels'].to(device)\n",
        "\n",
        "    # Generate predictions\n",
        "    with torch.no_grad():\n",
        "        predictions = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # Compare predictions with labels\n",
        "    masked_tokens = input_ids == custom_tokenizer.mask_token_id\n",
        "    correct_predictions += (predictions.logits.argmax(dim=-1) == labels).masked_select(masked_tokens).sum().item()\n",
        "    total_tokens += masked_tokens.sum().item()\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = (correct_predictions / total_tokens) * 100\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")\n"
      ]
    },
    
  ]
}
